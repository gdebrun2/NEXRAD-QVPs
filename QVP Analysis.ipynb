{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXRAD AWS QVP Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code downloads all radar data for a given set of WSR-88D radars between a start and end time, saves them to a chosen directory, and creates QVPs of reflectivity, cross-correlation coefficient, differential phase, and differential reflectivity as well as the vertical gradients and azimuthal variance of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import six\n",
    "import nexradaws\n",
    "import shutil\n",
    "from datetime import datetime \n",
    "import contextlib\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pyart\n",
    "from metpy.plots import USCOUNTIES\n",
    "import os \n",
    "import numpy as np\n",
    "import xarray \n",
    "import pandas as pd\n",
    "import logging\n",
    "from imp import reload\n",
    "import traceback\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from statsmodels import robust\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "%config InlineBackend.figure_format='retina' #Make figures high definition so they can be dragged into powerpoint without  saving them\n",
    "\n",
    "START = datetime(2020,2,25,18,0)\n",
    "END = datetime(2020,2,26,6,0)\n",
    "EVENT_DATE = ' ' + str(START)[:-9]\n",
    "\n",
    "RELEVANT_RADAR_IDS = ['KILX','KLOT','KDVN'] #change this to the radars of interest\n",
    "PATH = \"NEXRAD Scans/\" #the highest level directory for saving the files, logs, and figures\n",
    "DESIRED_ANGLES = [2,3,3.5,4,5,6.5,8,10,12,14,16,19] #Change this to the angle(s) of interest\n",
    "THRESHOLD = .7 #Minimum Percentage of scans over the interval that contain an angle of interest. If less than this, no QVP will be generated\n",
    "RELATIVE_ERROR_TOLERANCE = .25 #Maximum relative error between desired angle and the closest angle in the dataset. No QVP will be generated if relative error is greater. Set this higher to generate more QVPs\n",
    "\n",
    "#Radars in the Northeast, United States\n",
    "NE_Radars = [['KCLE', 'inland', 'Cleaveland', 'OH'],\n",
    "             ['KRLX', 'inland', 'Charleston', 'WV'],\n",
    "             ['KFCX', 'inland', 'Blacksburg', 'VA'],\n",
    "             ['KLWX', 'inland', 'Sterling', 'VA'],\n",
    "             ['KAKQ', 'coastal', 'Wakefield', 'VA'],\n",
    "             ['KDOX', 'coastal', 'Dover', 'DE'],\n",
    "             ['KDIX', 'coastal', 'Philadelphia', 'PA'],\n",
    "             ['KPBZ', 'inland', 'Pittsburgh', 'PA'],\n",
    "             ['KCCX', 'inland', 'State College', 'PA'],\n",
    "             ['KBGM', 'inland', 'Binghamton', 'NY'],\n",
    "             ['KBUF', 'inland', 'Buffalo', 'NY'],\n",
    "             ['KTYX', 'inland', 'Montague', 'NY'],\n",
    "             ['KENX', 'inland', 'Albany', 'NY'],\n",
    "             ['KOKX', 'coastal', 'New York City', 'NY'],\n",
    "             ['KBOX', 'coastal', 'Boston', 'MA'],\n",
    "             ['KCXX', 'inland', 'Burlington', 'VT'],\n",
    "             ['KGYX', 'coastal', 'Portland', 'ME'],\n",
    "             ['KCBW', 'inland', 'Caribou', 'ME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a map of all radar locations available to us througout the northeast\n",
    "\n",
    "locs = pyart.io.nexrad_common.NEXRAD_LOCATIONS\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "proj = ccrs.Miller()\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "extent = [-83, -65, 36, 48]\n",
    "ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m', color='black', linewidth=0.5)\n",
    "states_provinces = cfeature.NaturalEarthFeature(category='cultural', name='admin_1_states_provinces_lakes', scale='10m', facecolor='none')\n",
    "roads = cfeature.NaturalEarthFeature(category='cultural', name='roads', scale='10m', facecolor='none')\n",
    "ax.add_feature(states_provinces, edgecolor='black', linewidth=0.5)\n",
    "ax.add_feature(USCOUNTIES.with_scale('5m'), edgecolor='black', linewidth=0.2)\n",
    "ax.add_feature(roads, edgecolor='blue', linewidth=0.3)\n",
    "plt.title('NEXRAD Radar Locations - Northeast', fontweight='bold')\n",
    "\n",
    "for key in locs:\n",
    "    \n",
    "    lon = locs[key]['lon']\n",
    "    lat = locs[key]['lat']\n",
    "    name = key\n",
    "    ax.scatter(lon,lat,marker='o', color='black', transform=ccrs.PlateCarree())\n",
    "    lat_mod = lat + .2\n",
    "    lon_mod = lon - .4\n",
    "\n",
    "    if lon >= extent[0] and lon <= extent[1] and lat >= extent[2] and lat <= extent[3]:\n",
    "        ax.text(lon_mod, lat_mod, name, color='black', fontsize=14, transform=ccrs.PlateCarree())\n",
    "\n",
    "txt = 'University of Illinois'\n",
    "suppress = ax.text(.83, 0.105, txt, wrap=True, horizontalalignment='center', fontsize=12, fontweight='bold',transform=fig.transFigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data we download employs nine Volume Coverage Patterns (VCPs) to adequately sample the atmosphere based on weather conditions.\n",
    "A VCP is a series of 360 degree sweeps of the antenna at pre-determined elevation angles and pulse repetition frequencies completed in a specified period of time.\n",
    "The radar scan times 4.5, 5, 6 or 10 minutesdepending on the selected VCP. The NEXRAD products are divided into multiple data processing levels.\n",
    "The lower Level II data contain the three meteorological base data quantities at original resolution: reflectivity, mean radial velocity, and spectrum width.\n",
    "With the advent of dual polarization beginning in 2011, additional base products of differential reflectivity, correlation coefficient and differential phase are available.\n",
    "Mdm files are provided at the top of the hour. I believe these are summary files of the last hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tries to read in already present scan data. If the data is not present, download the files\n",
    "\n",
    "relevantFiles = {}\n",
    "\n",
    "for ID in RELEVANT_RADAR_IDS:\n",
    "    \n",
    "    radarPath = PATH+ID+EVENT_DATE\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        files = os.listdir(radarPath)\n",
    "        files.sort()\n",
    "        relevantFiles[ID] = [radarPath + '/' + file for file in files if 'MDM' not in file and '.' not in file and ID in file] #remove MDM and any other files\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        conn = nexradaws.NexradAwsInterface()\n",
    "        scans = conn.get_avail_scans_in_range(START, END, ID)\n",
    "\n",
    "        with contextlib.redirect_stdout(None):\n",
    "            results = conn.download(scans, radarPath) #Downloads all level 2 scans.\n",
    "            \n",
    "        files = os.listdir(radarPath)\n",
    "        files.sort()\n",
    "        relevantFiles[ID] = [radarPath + '/' + file for file in files if 'MDM' not in file]\n",
    "        \n",
    "    print(\"{}: There are {} scans available between {} and {}\\n\".format(ID, len(relevantFiles[ID]), START, END))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters:\n",
    "#    angles -- a 2D list of angles where each list represents a set of scan angles.\n",
    "#    DESIRED_ANGLES -- a global varaible representing the angles we want to generate QVPs for\n",
    "#    THRESHOLD -- The minimum percentage of scans that an angle must be present in\n",
    "#    RELATIVE_ERROR_TOLERANCE -- a global variable representing the acceptable relative error between our desired angle and the chosen angle\n",
    "#Returns a list of the angles that are closest to the DESIRED_ANGLES. Angles must be present in at least THRESHOLD percent of the scans throughout the interval.\n",
    "#It will choose the angle that has the lowest relative error that is below RELATIVE_ERROR_TOLERANCE.\n",
    "#Appends None if no such angle exists\n",
    "\n",
    "def find_closest_angles(angles, DESIRED_ANGLES, THRESHOLD, RELATIVE_ERROR_TOLERANCE):\n",
    "    \n",
    "    closestAngles = []\n",
    "    \n",
    "    for desiredAngle in DESIRED_ANGLES:\n",
    "        \n",
    "        argmins = []\n",
    "        argvals = []\n",
    "\n",
    "\n",
    "        for angleList in angles:\n",
    "\n",
    "            argmins.append(abs(np.array(angleList) - desiredAngle).argmin())\n",
    "            argvals.append(angleList[argmins[-1]])\n",
    "\n",
    "        valCounts = Counter(argvals)\n",
    "        uniqueVals = np.unique(argvals)\n",
    "        n = len(angles)\n",
    "\n",
    "        for val in uniqueVals:\n",
    "            if valCounts[val]/n < THRESHOLD:\n",
    "                uniqueVals = np.delete(uniqueVals,np.where(uniqueVals == val))\n",
    "\n",
    "        if len(uniqueVals) == 0:\n",
    "            return None\n",
    "\n",
    "        relativeErrors = abs(desiredAngle-uniqueVals)/desiredAngle\n",
    "        idx = relativeErrors.argmin()\n",
    "\n",
    "        if relativeErrors[idx] > RELATIVE_ERROR_TOLERANCE:\n",
    "            \n",
    "            closestAngles.append(None)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            closestAngles.append(uniqueVals[idx])\n",
    "    \n",
    "    return closestAngles\n",
    "\n",
    "#Returns a 2D list containing the angles of each scan over the interval for a given radar\n",
    "def generate_angles(radarID,files):\n",
    "    \n",
    "    angles = []\n",
    "    \n",
    "    for file in files[radarID]:\n",
    "        try:\n",
    "            \n",
    "            radar = pyart.io.read_nexrad_archive(file, include_fields = []) #not including the fields speeds us up .25s per file\n",
    "            angles.append(radar.fixed_angle['data'].tolist())\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            continue\n",
    "\n",
    "    return angles\n",
    "\n",
    "#Generates QVPs for a given scan (file) and desired angles\n",
    "#Returns a list of QVP dictionaries consisting of level II data averaged at all heights given for each angle\n",
    "def quasi_vertical_profile(filename, closestAngles, fields=None, gatefilter=None):\n",
    "    \n",
    "    qvps = []\n",
    "    \n",
    "    radar = pyart.io.read_nexrad_archive(filename)\n",
    "    \n",
    "    scanAngles = radar.fixed_angle['data']\n",
    "    \n",
    "    for closestAngle in closestAngles:\n",
    "        \n",
    "        if closestAngle not in scanAngles:\n",
    "            \n",
    "            qvps.append(None)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        qvp = {}\n",
    "        \n",
    "        index = np.where(scanAngles == closestAngle)[0][0]\n",
    "\n",
    "        if fields is None: #Goes through each file and finds the fields (i.e. reflectivity, cross correlation coefficient, etc. present. )\n",
    "            fields = radar.fields\n",
    "\n",
    "        for field in fields:\n",
    "            \n",
    "            thisField = radar.get_field(index, field).mean(axis = 0) #for each variable (i.e. reflectivity, cross correlation coefficient) calculate the mean at all heights given.\n",
    "            thisFieldStd = radar.get_field(index, field).std(axis = 0)\n",
    "            #thisFieldMad = pd.DataFrame(radar.get_field(index, field)).mad(axis=0)\n",
    "            thisFieldMad = robust.mad(radar.get_field(index, field),axis=0)\n",
    "            \n",
    "            qvp.update({field:thisField})\n",
    "            qvp.update({field+'_std':thisFieldStd})\n",
    "            qvp.update({field+'_mad':np.array(thisFieldStd)})\n",
    "\n",
    "        qvp.update({'range': radar.range['data'], 'time': radar.time}) #Updates range gates distance away from the radar\n",
    "        x,y,z = pyart.core.antenna_to_cartesian(qvp['range']/1000.0, 0.0, closestAngle) #Calculates range gates x,y, and height relative to distance away from the radar \n",
    "        qvp.update({'height': z})\n",
    "        qvps.append(qvp)\n",
    "    \n",
    "    return qvps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#We are going to loop through each file representative of a complete cycle of scans.  We will average the data and then \n",
    "#concatenate it into a pandas dataframe named after the individual variables\n",
    "#Saves all scan data to radarPath including error logs, a .txt of the scan angles and QVP Figures, Gradients and Standard Deviations\n",
    "#Will not generate QVP figures if the percentage of unusable scans from a radar exceeds THRESHOLD\n",
    "\n",
    "scanAngles = {} #Allows us to save and inspect the scan angles for each radar's scans\n",
    "unusableScans = 0\n",
    "\n",
    "for ID in RELEVANT_RADAR_IDS:\n",
    "\n",
    "    radarPath = PATH+ID+EVENT_DATE\n",
    "    \n",
    "    #see if angles have already been stored for this radar. If so, load them in. If not, generate them by reading the files. Saves a lot of time\n",
    "    try:\n",
    "\n",
    "        with open(radarPath + '/Available Angles','rb') as f:    \n",
    "            scanAngles[ID] = pickle.load(f)\n",
    "\n",
    "    except:\n",
    "\n",
    "        scanAngles[ID] = generate_angles(ID,relevantFiles)\n",
    "\n",
    "        with open(radarPath + '/Available Angles','wb') as f:\n",
    "            pickle.dump(scanAngles[ID],f)\n",
    "\n",
    "\n",
    "    closestAngles = find_closest_angles(scanAngles[ID],DESIRED_ANGLES,THRESHOLD,RELATIVE_ERROR_TOLERANCE) #find the closest angles for all the desired angles\n",
    "\n",
    "    for idx, closestAngle in enumerate(closestAngles.copy()):\n",
    "\n",
    "        if closestAngle == None:\n",
    "\n",
    "            print('No suitable angle for ' + ID, 'at ' + str(DESIRED_ANGLES[idx]) + ' degrees.')\n",
    "            closestAngles.remove(closestAngle)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        figurePath = radarPath + '/Figures/' + str(closestAngle)[:5]\n",
    "        \n",
    "        if os.path.exists(figurePath): #if figures for this angle already exists for this radar, we remove the angle to avoid redundancy\n",
    "            \n",
    "            closestAngles.remove(closestAngle)\n",
    "\n",
    "        else: #Otherwise, we make the directory to place figures into\n",
    "            \n",
    "            os.makedirs(figurePath)\n",
    "        \n",
    "    if len(closestAngles) == 0: #if all the figures for this radar have been generated, we go onto the next radar\n",
    "        \n",
    "        continue\n",
    "\n",
    "    all_qvps = [[] for i in range(len(closestAngles))] #we're going to append the qvps for each angle to the corresponding list\n",
    "\n",
    "    for file_idx in range(len(relevantFiles[ID])):\n",
    "\n",
    "        try:\n",
    "\n",
    "            returned_qvps = quasi_vertical_profile(relevantFiles[ID][file_idx],closestAngles)\n",
    "\n",
    "            for qvp_idx, qvp in enumerate(returned_qvps):\n",
    "\n",
    "\n",
    "                if qvp == None:\n",
    "\n",
    "                    continue\n",
    "\n",
    "                all_qvps[qvp_idx].append(qvp)\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            reload(logging) #ipython will override your logging handler so you must reload\n",
    "            logging.basicConfig(filename=radarPath + '/Pyart File Read Errors.log', encoding='utf-8', level=logging.DEBUG) #at least one scan is unreadable\n",
    "\n",
    "            debugString= ' filename='+relevantFiles[ID][idx] + ' index=' + str(idx) + ' at ' + str(datetime.now().time())[:-5]\n",
    "            logging.debug(debugString)\n",
    "            logging.exception(e)\n",
    "\n",
    "            if 'index 0 is out of bounds for axis 0 with size 0' in str(e):     #this is the error thrown by unreadable files, so increment unusableScans\n",
    "                unusableScans +=1\n",
    "\n",
    "            #print(traceback.format_exc())\n",
    "\n",
    "    for idx, qvp_list in enumerate(all_qvps):\n",
    "                \n",
    "        reflectivities = pd.DataFrame()\n",
    "        reflectivities_std = pd.DataFrame()\n",
    "        reflectivities_mad = pd.DataFrame()\n",
    "        differential_phases = pd.DataFrame()\n",
    "        differential_phases_std = pd.DataFrame()\n",
    "        differential_phases_mad = pd.DataFrame()\n",
    "        cross_correlation_ratios = pd.DataFrame()\n",
    "        cross_correlation_ratios_std = pd.DataFrame()\n",
    "        cross_correlation_ratios_mad = pd.DataFrame()\n",
    "        spectrum_widths = pd.DataFrame()\n",
    "        spectrum_widths_std = pd.DataFrame()\n",
    "        spectrum_widths_mad = pd.DataFrame()\n",
    "        differential_reflectivities = pd.DataFrame()\n",
    "        differential_reflectivities_std = pd.DataFrame()\n",
    "        differential_reflectivities_mad = pd.DataFrame()\n",
    "        heights = pd.DataFrame()\n",
    "        times = []\n",
    "                \n",
    "        for qvp in qvp_list:\n",
    "            \n",
    "            reflectivity = pd.DataFrame(qvp['reflectivity']).T\n",
    "            differential_phase = pd.DataFrame(qvp['differential_phase']).T\n",
    "            cross_correlation_ratio = pd.DataFrame(qvp['cross_correlation_ratio']).T\n",
    "            spectrum_width = pd.DataFrame(qvp['spectrum_width']).T\n",
    "            differential_reflectivity = pd.DataFrame(qvp['differential_reflectivity']).T\n",
    "            height = pd.DataFrame(qvp['height']).T\n",
    "\n",
    "            reflectivity_std = pd.DataFrame(qvp['reflectivity_std']).T\n",
    "            differential_phase_std = pd.DataFrame(qvp['differential_phase_std']).T\n",
    "            cross_correlation_ratio_std = pd.DataFrame(qvp['cross_correlation_ratio_std']).T\n",
    "            spectrum_width_std = pd.DataFrame(qvp['spectrum_width_std']).T\n",
    "            differential_reflectivity_std = pd.DataFrame(qvp['differential_reflectivity_std']).T\n",
    "            \n",
    "            reflectivity_mad = pd.DataFrame(qvp['reflectivity_mad']).T\n",
    "            differential_phase_mad = pd.DataFrame(qvp['differential_phase_mad']).T\n",
    "            cross_correlation_ratio_mad = pd.DataFrame(qvp['cross_correlation_ratio_mad']).T\n",
    "            spectrum_width_mad = pd.DataFrame(qvp['spectrum_width_std']).T\n",
    "            differential_reflectivity_mad = pd.DataFrame(qvp['differential_reflectivity_mad']).T\n",
    "\n",
    "            reflectivities = pd.concat([reflectivities, reflectivity]) #concatenates qvp for reflectivity we just calculated with all of the other qvps such that we get a time series of all the qvps from each file\n",
    "            differential_phases = pd.concat([differential_phases, differential_phase])\n",
    "            cross_correlation_ratios = pd.concat([cross_correlation_ratios, cross_correlation_ratio])\n",
    "            spectrum_widths= pd.concat([spectrum_widths, spectrum_width])\n",
    "            differential_reflectivities = pd.concat([differential_reflectivities, differential_reflectivity])\n",
    "\n",
    "            reflectivities_std = pd.concat([reflectivities_std, reflectivity_std])\n",
    "            differential_phases_std = pd.concat([differential_phases_std, differential_phase_std])\n",
    "            cross_correlation_ratios_std = pd.concat([cross_correlation_ratios_std, cross_correlation_ratio_std])\n",
    "            spectrum_widths_std = pd.concat([spectrum_widths_std, spectrum_width_std])\n",
    "            differential_reflectivities_std = pd.concat([differential_reflectivities_std, differential_reflectivity_std])\n",
    "            \n",
    "            reflectivities_mad = pd.concat([reflectivities_mad, reflectivity_mad])\n",
    "            differential_phases_mad = pd.concat([differential_phases_mad, differential_phase_mad])\n",
    "            cross_correlation_ratios_mad = pd.concat([cross_correlation_ratios_mad, cross_correlation_ratio_mad])\n",
    "            spectrum_widths_mad = pd.concat([spectrum_widths_mad, spectrum_width_mad])\n",
    "            differential_reflectivities_mad = pd.concat([differential_reflectivities_mad, differential_reflectivity_mad])\n",
    "\n",
    "\n",
    "            heights = pd.concat([heights, height])\n",
    "            times.append(qvp['time']['units'][14:-1])\n",
    "                \n",
    "        \n",
    "        \n",
    "        #In order to do a pcolormesh you need three equal sized arrays of time,height,and then the variable you want to plot.\n",
    "        #Creates a 2d array of time that is the same size as our height and variable arrays/dataframes\n",
    "        #creates pandas dataframe by repeating the times n number of times where n is the size of the height array in the y direction \n",
    "\n",
    "        times = pd.DataFrame(pd.to_datetime(times))\n",
    "        n = reflectivities.shape[1]\n",
    "        times_modified = pd.concat([times] * (n), axis=1, ignore_index=True) \n",
    "        new_reflectivities = reflectivities.copy(deep = True)\n",
    "\n",
    "        df = new_reflectivities\n",
    "        df.index = np.arange(0, df.shape[0], 1)\n",
    "        s=df.isnull().stack()\n",
    "        s=s.groupby(level=0).cumsum()[~s]\n",
    "        s=s.groupby([s.index.get_level_values(0),s]).transform('count').unstack().reindex_like(df)\n",
    "\n",
    "\n",
    "        reflectivities_deep = reflectivities.copy(deep = True)\n",
    "        reflectivities_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        differential_phases_deep = differential_phases.copy(deep = True)\n",
    "        differential_phases_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        cross_correlation_ratios_deep = cross_correlation_ratios.copy(deep = True)\n",
    "        cross_correlation_ratios_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        differential_reflectivities_deep = differential_reflectivities.copy(deep = True)\n",
    "        differential_reflectivities_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        reflectivities_std_deep = reflectivities_std.copy(deep = True)\n",
    "        reflectivities_std_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        differential_phases_std_deep = differential_phases_std.copy(deep = True)\n",
    "        differential_phases_std_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        cross_correlation_ratios_std_deep = cross_correlation_ratios_std.copy(deep = True)\n",
    "        cross_correlation_ratios_std_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        differential_reflectivities_std_deep = differential_reflectivities_std.copy(deep = True)\n",
    "        differential_reflectivities_std_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "        \n",
    "        reflectivities_mad_deep = reflectivities_mad.copy(deep = True)\n",
    "        reflectivities_mad_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        differential_phases_mad_deep = differential_phases_mad.copy(deep = True)\n",
    "        differential_phases_mad_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        cross_correlation_ratios_mad_deep = cross_correlation_ratios_mad.copy(deep = True)\n",
    "        cross_correlation_ratios_mad_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "\n",
    "        differential_reflectivities_mad_deep = differential_reflectivities_mad.copy(deep = True)\n",
    "        differential_reflectivities_mad_deep.index = np.arange(0, reflectivities_deep.shape[0], 1)\n",
    "        \n",
    "        closestAngle = closestAngles[idx]\n",
    "        figurePath = radarPath + '/Figures/' + str(closestAngle)[:5]\n",
    "\n",
    "\n",
    "        #Reflectivity QVP\n",
    "        ymin = 0\n",
    "        ymax = 12\n",
    "\n",
    "        cmap_reflectivity = mpl.colors.ListedColormap(['#e3fdfe','#d7d2e7','#cbb1d2','#9d80a4','#6d4b74','#d6d4b1','#a9a882','#777777','#6be9ea','#469eef','#0e00ec','#75fb4c','#5ac53a','#3f8e27','#feff54','#e1c140','#f09636','#ea3423','#ca2A1d','#b02318','#ea33f7','#8f59c3'])\n",
    "        bounds_reflectivity = [-35, -30, -25, -20, -15, -10, -5, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]\n",
    "        norm_reflectivity = mpl.colors.BoundaryNorm(bounds_reflectivity, cmap_reflectivity.N)\n",
    "\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, reflectivities_deep[(s>5) & (reflectivities_deep > 0)].T, cmap=cmap_reflectivity, norm = norm_reflectivity)\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Reflectivity QVP '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Reflectivity QVP.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Reflectivity QVP Gradient\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, reflectivities_deep[(s>5) & (reflectivities_deep > 0)].T.diff(10, axis = 0) * -1, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Reflectivity QVP Gradient '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Reflectivity Gradient.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Reflectivity Standard Deviations\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, reflectivities_std_deep[(s>5) & (reflectivities_std_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Reflectivity Standard Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Reflectivity Standard Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "        \n",
    "        #Reflectivity MAD\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, reflectivities_mad_deep[(s>5) & (reflectivities_mad_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Reflectivity Mean Absolute Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Reflectivity Mean Absolute Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Differential Phase QVP\n",
    "        cmap_kdp = mpl.colors.ListedColormap(['#a5a5a5','#7f7f7f','#6f1812','#a62a1f','#e73755','#ea95ba','#c694e7','#7d41bd','#5623bc','#73f6fc','#5eb5de','#2f6fba','#4a9b62','#6fcc78','#80f6af','#79fb54','#feff54','#f9da78','#df8344','#ffffff'])\n",
    "        bounds_kdp = [-0.3, -0.1, 0, 0.02, 0.04, 0.07, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 10, 30]\n",
    "        norm_kdp = mpl.colors.BoundaryNorm(bounds_kdp, cmap_kdp.N)\n",
    "\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_phases_deep[s > 5].T, cmap=cmap_kdp, norm = norm_kdp)\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 14)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 14)\n",
    "        plt.title(ID + ' Differential Phase QVP ' + str(closestAngle)[:-5] + ' Degrees' + EVENT_DATE, fontsize = 18)\n",
    "        plt.colorbar(cs, pad=0.05)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Phase QVP.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Differential Phase Gradient\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_phases_deep[(s>5) & (differential_phases_deep > 0)].T.diff(10, axis = 0) * -1, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Phase Gradient '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Phase Gradient.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Differential Phase Standard Deviations\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_phases_std_deep[(s>5) & (differential_phases_std_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Phase Standard Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Phase Standard Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "        \n",
    "        #Differential Phase MAD\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_phases_mad_deep[(s>5) & (differential_phases_mad_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Phase Mean Absolute Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Phase Mean Absolute Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Cross Correlation Coefficient QVP\n",
    "        cmap_cc = mpl.colors.ListedColormap(['#95949b','#151486','#0d01e0','#8987d1','#8dfc71','#9acd3f','#fefb53','#f5c644','#df8f35','#ea4425','#d12c1e','#941c12','#6f1357','#efb0cf','#6d1379'])\n",
    "        bounds_cc = [0.2, 0.45, 0.65, 0.75, 0.8, 0.85, 0.90, 0.93, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00, 1.05, 3]\n",
    "        norm_cc = mpl.colors.BoundaryNorm(bounds_cc, cmap_cc.N)\n",
    "\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, cross_correlation_ratios_deep[(s>5) & (reflectivities_deep > 0)].T, norm = norm_cc, cmap = cmap_cc)\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Cross Correlation Coefficient QVP ' + str(closestAngle)[:-5] + ' Degrees' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Cross Correlation QVP.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Cross Correlation Coefficient Gradient\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, cross_correlation_ratios_deep[(s>5) &\n",
    "                                                                                                              (cross_correlation_ratios_deep > 0)].T.diff(10, axis = 0) * -1, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Cross Correlation Coefficient Gradient '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Cross Correlation Gradient.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Cross Correlation Coefficient Standard Deviations\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, cross_correlation_ratios_std_deep[(s>5) & (cross_correlation_ratios_std_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Cross Correlation Coefficient Standard Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Cross Correlation Coefficient Standard Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "        \n",
    "        #Cross Correlation Coefficient MAD\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, cross_correlation_ratios_mad_deep[(s>5) & (cross_correlation_ratios_mad_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Cross Correlation Coefficient Mean Absolute Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Cross Correlation Coefficient Mean Absolute Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        #Differential Reflectivity QVP\n",
    "        cmap_zdr = mpl.colors.ListedColormap(['#404040','#9c9c9c','#c9c9c9','#8879b0','#050092','#4B96ce','#83fbd4','#7dd868','#ffff7a','#F09655','#c82a1d','#9f1f14','#e888bc','#ffffff','#6d1379'])\n",
    "        bounds_zdr = [-4, -2, -0.5, 0, 0.3, 0.6, 1, 1.5, 2, 2.5, 3, 4, 5, 6, 8, 20]\n",
    "        norm_zdr = mpl.colors.BoundaryNorm(bounds_zdr, cmap_zdr.N)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize = (15, 5))\n",
    "        cs = ax.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_reflectivities_deep[(s>5) & (reflectivities_deep > 0)].T, cmap=cmap_zdr, norm = norm_zdr)\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Reflectivity QVP ' + str(closestAngle)[:-5] + ' Degrees' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Reflectivity QVP.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Differential Reflectivity Gradient\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_reflectivities_deep[(s>5) &\n",
    "                                                                                                                 (differential_reflectivities_deep > 0)].T.diff(10, axis = 0) * -1, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Reflectivity Gradient '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Reflectivity Gradient.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        #Differential Reflectivity Standard Deviations\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_reflectivities_std_deep[(s>5) & (differential_reflectivities_std_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Reflectivity Standard Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Reflectivity Standard Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "        \n",
    "        #Differential Reflectivity MAD\n",
    "        plt.figure(figsize = (15, 5))\n",
    "        cs = plt.pcolormesh(times_modified.loc[:, 0], heights.loc[0, :].T/1000, differential_reflectivities_mad_deep[(s>5) & (differential_reflectivities_mad_deep > 0)].T, cmap='seismic')\n",
    "        plt.ylabel('Height (km ASL)', fontsize = 20)\n",
    "        plt.xlabel('Time (UTC)', fontsize = 20)\n",
    "        plt.title(ID + ' Differential Reflectivity Mean Absolute Deviations '+ str(closestAngle)[:-5] + ' Degrees ' + EVENT_DATE, fontsize = 18)\n",
    "        cbar = plt.colorbar(cs, pad=0.005)\n",
    "        cbar.ax.tick_params(labelsize = 16)\n",
    "        xformatter = md.DateFormatter('%H:%M')\n",
    "        xlocator = md.MinuteLocator(byminute=[0])\n",
    "        plt.gcf().axes[0].xaxis.set_major_formatter(xformatter)\n",
    "        plt.tick_params(labelsize = 18)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(figurePath + '/Differential Reflectivity Mean Absolute Deviations.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "        print(ID + ' ' + str(closestAngle) + ' degrees: Done!')\n",
    "\n",
    "print('Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RadarMeteorology",
   "language": "python",
   "name": "radarmeteorology"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
